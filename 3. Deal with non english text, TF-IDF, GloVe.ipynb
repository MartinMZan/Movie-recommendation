{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc29c55a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import string\n",
    "import nltk\n",
    "from nltk.stem.snowball import EnglishStemmer\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "from scipy.spatial import distance\n",
    "\n",
    "import time\n",
    "\n",
    "# nltk.download('words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "84475f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_raw(str):\n",
    "    # Remove punctuation\n",
    "    str = [char for char in str if char not in string.punctuation]\n",
    "    str = ''.join(str)\n",
    "    \n",
    "    # And use stemmer\n",
    "    str = str.split(' ')\n",
    "    str = [stemmer.stem(word) for word in str]\n",
    "    str = ' '.join(str)\n",
    "    \n",
    "    return str\n",
    "\n",
    "def remove_non_english(str):\n",
    "    str = str.split(' ')\n",
    "    str = [word for word in str if word in englishwords]\n",
    "    str = ' '.join(str)\n",
    "    \n",
    "    return str\n",
    "\n",
    "def load_glove_model(File):\n",
    "    glove_model = {}\n",
    "    with open(File,'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            split_line = line.split()\n",
    "            word = split_line[0]\n",
    "            embedding = np.array(split_line[1:], dtype=np.float64)\n",
    "            glove_model[word] = embedding\n",
    "    return glove_model\n",
    "\n",
    "def map_overview(line):\n",
    "    overviewvector = np.array([])\n",
    "    for word in line.split():\n",
    "        try:\n",
    "            overviewvector = np.concatenate([overviewvector, glove[word]], axis=0)\n",
    "        except KeyError:\n",
    "            pass\n",
    "    \n",
    "    if len(overviewvector) == 0:\n",
    "        return []\n",
    "    \n",
    "    # Change data structure to [ [], [], [] ... ] format\n",
    "    ovec2 = np.zeros(shape=(int(len(overviewvector)/wordlength), wordlength))\n",
    "    for i in range( int(len(overviewvector)/wordlength) ) :\n",
    "        ovec2[i] = overviewvector[i * wordlength : i * wordlength + wordlength]\n",
    "    \n",
    "    return ovec2\n",
    "\n",
    "def avg_of_words(line):\n",
    "    \n",
    "    if len(line) == 0:\n",
    "        return []\n",
    "    \n",
    "    # Calculate the center of the points\n",
    "    line = sum(line)/len(line)\n",
    "    \n",
    "    return line"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61f26632",
   "metadata": {},
   "source": [
    "Separate movies to 2 files based on overview column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ef738a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = pd.read_csv('movies_metadata.csv', low_memory=False)\n",
    "\n",
    "movieswithoverview = movies[movies['overview'].notnull()]\n",
    "movies = movies[movies['overview'].isnull()]\n",
    "\n",
    "## Write\n",
    "# movies.to_csv('1a movies_withoutoverview.csv', index=False)\n",
    "# movieswithoverview.to_csv('1b movies_withoverview.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd765a93",
   "metadata": {},
   "source": [
    "1. part: Deal with non-english text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4faf4c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read and select movies with overview\n",
    "movieswithoverview = pd.read_csv('1b movies_withoverview.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "459ce9c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use stemmer\n",
    "stemmer = EnglishStemmer()\n",
    "movieswithoverview['overview'] = movieswithoverview['overview'].apply(text_to_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "faad738f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get rid of non english text\n",
    "# This took me at least 1 hour to run!\n",
    "englishwords = nltk.corpus.words.words()\n",
    "movieswithoverview['overview'] = movieswithoverview['overview'].apply(remove_non_english)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f614823c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Write to file\n",
    "#movieswithoverview.dropna(inplace=True)\n",
    "#movieswithoverview.to_csv('2 movies_english.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6bff391",
   "metadata": {},
   "source": [
    "2. part: TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fb2b3407",
   "metadata": {},
   "outputs": [],
   "source": [
    "movieswithoverview = pd.read_csv('2 movies_english.csv', low_memory=False)\n",
    "\n",
    "tfidf = TfidfVectorizer(lowercase=True, stop_words='english')\n",
    "vector = tfidf.fit_transform(movieswithoverview['overview'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "07c6fb72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<44392x11872 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 719497 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The number of words is reduced to ~12 000\n",
    "vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b40a96ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dimension reduction\n",
    "k = 50 # Number of components\n",
    "svd = TruncatedSVD(n_components=k)\n",
    "vector = svd.fit_transform(vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "40934a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store vector into dataframe and join them\n",
    "components = pd.DataFrame(vector, columns=[str(i) + '. overview component' for i in range(0,k)])\n",
    "\n",
    "movieswithcomponents = movieswithoverview.join(components).drop('overview', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "745901e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Write to file\n",
    "# movieswithcomponents.to_csv('3a movies_TFIDF.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "498ce767",
   "metadata": {},
   "source": [
    "3. part: GloVe model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8b8dda76",
   "metadata": {},
   "outputs": [],
   "source": [
    "movieswithoverview = pd.read_csv('2 movies_english.csv', low_memory=False)\n",
    "\n",
    "glove = load_glove_model('glove.6B.50d.txt')\n",
    "wordlength = len(glove[list(glove.keys())[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "213ce8d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply GloVe vectors\n",
    "movieswithoverview['overview'] = movieswithoverview['overview'].apply(map_overview)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ce180200",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average (center) of words method\n",
    "movieswithoverview_avg = movieswithoverview\n",
    "movieswithoverview_avg['overview'] = movieswithoverview['overview'].apply(avg_of_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b5c0bcba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vector to different columns\n",
    "components = pd.DataFrame(movieswithoverview_avg['overview'].to_list(), columns=[str(col) + '. overview component' for col in range(len(movieswithoverview['overview'][0]))])\n",
    "components = components.fillna(value=0)\n",
    "\n",
    "movieswithoverview_avg = movieswithoverview_avg.drop('overview', axis=1).join(components)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e39386b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Write to file\n",
    "# movieswithoverview_avg.to_csv('3b movies_GloVe.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f22d0c4",
   "metadata": {},
   "source": [
    "Example how the text changed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "326674e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Zhigen, an old Chinese farmer, has lived alone in Beijing for over 20 years after moving to the city to allow his son Chongyi to attend university. He decides to make the long journey from Beijing to Yangshuo to honour the promise he made to his wife to bring back the bird that has been his only companion in the city. His daughter-in-law Qianying, a beautiful rich career woman, asks him to take along his granddaughter Renxing, an only child brought up in the lap of luxury. While grandfather and granddaughter set out on their journey - one travelling back in time, the other discovering her roots - Chongyi and Qianying, ponder the meaning of the life they have led in the sole pursuit of success and money.'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msg = movieswithoverview['overview'][40000]\n",
    "msg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b9e51458",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'an old farmer live in for over year after move to the to allow his son to attend he to make the long journey from to to the he made to his wife to bring back the bird that been his companion in the his a beauti rich career woman ask him to take along his an child brought up in the lap of while and set out on their journey one travel back in time the other her root and ponder the mean of the life they have led in the sole pursuit of success and money'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmer = EnglishStemmer()\n",
    "englishwords = nltk.corpus.words.words()\n",
    "msg = text_to_raw(msg)\n",
    "msg = remove_non_english(msg)\n",
    "msg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdcd81fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
